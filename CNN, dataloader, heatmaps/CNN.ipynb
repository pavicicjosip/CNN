{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ce46603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7880bda8",
   "metadata": {},
   "source": [
    "## ImageAugmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db0ee681",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageAugmentation:\n",
    "    def __init__(self, path = \"./\"):\n",
    "        self.dim = (64, 36)\n",
    "        self.folder_list = glob.glob(path + \"/*\")\n",
    "        self.folders = []\n",
    "        for p in self.folder_list:\n",
    "            self.folders.append(p.split(\"\\\\\")[-1])\n",
    "            \n",
    "        \n",
    "        \n",
    "        for folder in self.folders:\n",
    "            self.files = glob.glob(path + \"/\" + folder + \"/*\")\n",
    "            \n",
    "            for file in self.files:\n",
    "                #resize\n",
    "                file_name = file.split(\"\\\\\")[-1]\n",
    "                img = cv2.imread(path + \"/\" + folder + \"/\" + file_name)\n",
    "                resized = cv2.resize(img, self.dim,interpolation=cv2.INTER_AREA)                \n",
    "                cv2.imwrite(path + \"/\" + folder + \"/\" + file_name,resized)\n",
    "                \n",
    "                \n",
    "                constraint = [\"rx_\", \"ry_\"]\n",
    "                if file_name[:3] not in constraint and path.split('/')[-1] != 'test':\n",
    "                    rows, cols, dim = resized.shape\n",
    "                    My = np.float32([[-1,  0, cols],\n",
    "                                    [0 ,  1, 0   ],\n",
    "                                    [0 ,  0, 1   ]])\n",
    "                    Mx = np.float32([[1,  0, 0],\n",
    "                                    [0 ,  -1, rows],\n",
    "                                    [0 ,  0, 1   ]])\n",
    "                    #resized img reflection on y axis\n",
    "                    reflected_img = cv2.warpPerspective(resized,My,(int(cols),int(rows)))\n",
    "                    cv2.imwrite(path + \"/\" + folder + \"/\" + \"ry_\"+ file_name,reflected_img)\n",
    "                    \n",
    "                    #resized img reflection on x axis\n",
    "                    reflected_img = cv2.warpPerspective(resized,Mx,(int(cols),int(rows)))\n",
    "                    cv2.imwrite(path + \"/\" + folder + \"/\" + \"rx_\"+ file_name,reflected_img)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cdeb289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ImageAugmentation at 0x27d55129700>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ImageAugmentation(\"./data/train\")\n",
    "ImageAugmentation(\"./data/test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d850c977",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af34e0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDataset(Dataset):\n",
    "    def __init__(self, train = False, test = False):\n",
    "        if(train):\n",
    "            self.data_path = \"./data/train/\"\n",
    "        if(test):\n",
    "            self.data_path = \"./data/test/\"\n",
    "        self.folder_list = glob.glob(self.data_path + \"*\")\n",
    "\n",
    "        self.data = []\n",
    "        for folder in self.folder_list:\n",
    "            folder_name = folder.split(\"\\\\\")[-1]\n",
    "            for img_path in glob.glob(self.data_path + folder_name + \"/*.jpg\"):\n",
    "                self.data.append([img_path, folder_name])\n",
    "        self.class_map = {\"Car\": 0, \"Truck\": 1, \"Bicycle\": 2, \"Dog\": 3}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        img_path, class_name = self.data[i]\n",
    "        img = cv2.imread(img_path)\n",
    "        class_id = self.class_map[class_name]\n",
    "        img_tensor = torch.tensor(img, dtype=torch.float)\n",
    "        img_tensor = img_tensor.permute(2,0,1)\n",
    "        class_id = torch.tensor([class_id])\n",
    "        return img_tensor, class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25bf4eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    batch_size = 5\n",
    "    train_dataset = CDataset(train=True)\n",
    "    data_loader_train = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    test_dataset = CDataset(test=True)\n",
    "    data_loader_test = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e6c961",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd5ce841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d27159ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\") \n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d7b2c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.gradients = None\n",
    "\n",
    "        self.conv_layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.PReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.PReLU(),  \n",
    "            \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.PReLU(),  \n",
    "            \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Dropout(p=0.6),\n",
    "            nn.Linear(9216, 1028),\n",
    "            nn.PReLU(),\n",
    "            nn.Dropout(p=0.6),\n",
    "            nn.Linear(1028, 128),\n",
    "            nn.PReLU(),\n",
    "            nn.Dropout(p=0.6),\n",
    "            nn.Linear(128, len(train_dataset.class_map)),\n",
    "            nn.PReLU(),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x): \n",
    "        x = self.conv_layer(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc_layer(x)\n",
    "        return x      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fd468bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9216"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = CNN()\n",
    "def calc_input_dims():\n",
    "        batch_data = torch.zeros((1, 3, 64, 36))\n",
    "        \n",
    "        batch_data = net.conv_layer(batch_data)\n",
    "        \n",
    "        return int(np.prod(batch_data.size()))\n",
    "calc_input_dims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5630198e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossF = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af58407b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch #0\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n",
      "torch.Size([5, 3, 36, 64])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-606be9461452>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mrunning_loss_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cuda:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_loader_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[1;31m# inputs, labels = data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ppz\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ppz\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    555\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    558\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ppz\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ppz\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-ef52412a3fe6>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mimg_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mclass_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mimg_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net.to(device)  \n",
    "epochs = 50\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "\n",
    "for epoch in range(epochs): \n",
    "    print(\"Starting epoch #\" + str(epoch))\n",
    "    running_loss_train = 0.0\n",
    "    running_loss_test = 0.0\n",
    "    net.to(torch.device(\"cuda:0\")) \n",
    "    for i, data in enumerate(data_loader_train, 0):\n",
    "        # inputs, labels = data\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = lossF(outputs, labels.flatten())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss_train += loss.item()\n",
    "    \n",
    "    net.to(torch.device(\"cpu\")) \n",
    "    with torch.no_grad():\n",
    "        for data in data_loader_test:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "\n",
    "            loss = lossF(outputs, labels.flatten())\n",
    "            running_loss_test += loss.item()\n",
    "    \n",
    "    train_loss.append(float(running_loss_train))\n",
    "    test_loss.append(float(running_loss_test)) \n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c19a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(epochs)\n",
    "y_train = np.array(train_loss) \n",
    "y_test = np.array(test_loss)\n",
    "plt.title('Loss over epochs (b=train, r=test)')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Misclassification rate/loss')\n",
    "plt.plot(x, y_train, c='b')\n",
    "plt.plot(x, y_test, c='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9e95e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(epochs)\n",
    "y_test = np.array(test_loss)\n",
    "plt.title('Loss over epochs (b=train, r=test)')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Misclassification rate/loss')\n",
    "plt.plot(x, y_test, c='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c01666",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.to(torch.device(\"cpu\")) \n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "predict = []\n",
    "true = []\n",
    "\n",
    "def find_max_elem(array):\n",
    "    _max = float('-inf')\n",
    "    index = 0\n",
    "    for i in range(len(array)):\n",
    "        if array[i] > _max:\n",
    "            index = i\n",
    "            _max = array[i]\n",
    "    return index\n",
    "            \n",
    "with torch.no_grad():\n",
    "    for data in data_loader_test:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            try:\n",
    "                true.append(int(labels[i]))\n",
    "                predict.append(find_max_elem(outputs[i]))\n",
    "                if find_max_elem(outputs[i]) == labels[i]:\n",
    "                    correct += 1\n",
    "                total+=1\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    print(correct, total)\n",
    "\n",
    "print('Accuracy on test images: %d %%' % (\n",
    "    round(100 * correct / total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9085b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(true, predict)\n",
    "\n",
    "class Confusion_matrix():\n",
    "    def __init__(self):\n",
    "        self.M = []\n",
    "        self.class_map = {\"Car\": 0, \"Truck\": 1, \"Bicycle\": 2, \"Dog\": 3}\n",
    "\n",
    "    def extract_all(self, CM):\n",
    "        for k in range(4):\n",
    "            tp, fn, fp, tn = 0, 0, 0, 0\n",
    "            for i in range(4):\n",
    "                for j in range(4):\n",
    "                    if i == j and i == k:\n",
    "                        tp = CM[i][j]\n",
    "                    elif i == k and (j > i or j < i):\n",
    "                        fn += CM[i][j]\n",
    "                    elif j == k and (i > j or i < j):\n",
    "                        fp += CM[i][j]\n",
    "                    else:\n",
    "                        tn += CM[i][j]\n",
    "            self.M.append([tn, fp, fn, tp])  \n",
    "            \n",
    "            \n",
    "        for i in range(4):\n",
    "            position = list(self.class_map.values()).index(i)\n",
    "            print(\"Class: \", list(self.class_map.keys())[position])\n",
    "            print(\"[tn, fp, fn, tp]: \", self.M[i])\n",
    "            print(\"Accuracy: \", self.accuracy(i))\n",
    "            print(\"Misclassification: \", self.misclassification(i))\n",
    "            print(\"Precision: \", self.precision(i))\n",
    "            print(\"Recall: \", self.recall(i))\n",
    "            print(\"*********************************************\")\n",
    "    \n",
    "    def tn_fp_fn_tp(self, _class):\n",
    "        return self.M[_class]\n",
    "    \n",
    "    def accuracy(self, _class):\n",
    "        tn, fp, fn, tp = self.M[_class]\n",
    "        return (tp+tn)/(tp+tn+fp+fn) * 100\n",
    "    \n",
    "    def misclassification(self, _class):\n",
    "        tn, fp, fn, tp = self.M[_class]\n",
    "        return (fp+fn)/(tp+tn+fp+fn) * 100\n",
    "    \n",
    "    def precision(self, _class):\n",
    "        tn, fp, fn, tp = self.M[_class]\n",
    "        return tp/(tp+fp) * 100\n",
    "    \n",
    "    def recall(self, _class):\n",
    "        tn, fp, fn, tp = self.M[_class]\n",
    "        return tp/(tp+fn) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4b6748",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Confusion_matrix()\n",
    "a.extract_all(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42847f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PATH = \"./CNNmodule1\"\n",
    "#torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcfca68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#net = CNN()\n",
    "#net.load_state_dict(torch.load(PATH))\n",
    "#net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8da34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating number of parameters in CNN\n",
    "X = [(3, 32, 3),(32, 64, 3),(64, 64, 3)]\n",
    "Y = [(9216,1028),(1028,128),(128,4)]\n",
    "num_param = 0\n",
    "for x in X:\n",
    "    num_param += (x[2] * x[2] * x[0] + 1 )*x[1]\n",
    "for y in Y:\n",
    "    num_param += y[0] * y[1] + 1 * y[1]\n",
    "num_param"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
