{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb9402a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from ipynb.fs.defs. Convolutional_neural_network import CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4562d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv_layer): Sequential(\n",
       "    (0): Conv2d(3, 128, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): PReLU(num_parameters=1)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(128, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): PReLU(num_parameters=1)\n",
       "    (7): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): PReLU(num_parameters=1)\n",
       "    (11): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): PReLU(num_parameters=1)\n",
       "    (14): AvgPool2d(kernel_size=15, stride=1, padding=0)\n",
       "  )\n",
       "  (fc_layer): Sequential(\n",
       "    (0): Dropout(p=0.6, inplace=False)\n",
       "    (1): Linear(in_features=384, out_features=6, bias=True)\n",
       "    (2): PReLU(num_parameters=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = \"./SimpsonsCNN\"\n",
    "net = CNN()\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "defe3788",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = {\"abraham_grampa_simpson\": 0, \"bart_simpson\": 1, \n",
    "             \"homer_simpson\": 2, \"lisa_simpson\": 3, \n",
    "             \"marge_simpson\": 4,  \"principal_skinner\": 5}   \n",
    "\n",
    "path = './Data/heatmaps/homer_simpson/pic_0001.jpg'\n",
    "img = cv2.imread(path)\n",
    "img = torch.tensor(img, dtype=torch.float)\n",
    "img = img.permute(2,0,1).unsqueeze(0)\n",
    "label = class_map[path.split('/')[-2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22a40065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(384, 15, 15)\n",
      "(6, 384)\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "gap_weights = np.array(net.fc_layer[1].weight.detach())\n",
    "parameters = np.array(torch.squeeze(net.conv_layer[:14](img)).detach())\n",
    "print(parameters.shape)\n",
    "print(gap_weights.shape)\n",
    "\n",
    "w = 15\n",
    "h = 15\n",
    "d = 100\n",
    "\n",
    "CAM = np.zeros((w, h))\n",
    "for x in range(w):\n",
    "    for y in range(h):\n",
    "        for k in range(d):\n",
    "            CAM[x][y] += gap_weights[int(label)][k] * parameters[k][x][y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8a96f0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path = './Data/heatmaps/homer_simpson/pic_0001.jpg'\n",
    "img = cv2.imread(path)\n",
    "img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "heatmap = cv2.resize(CAM, (img.shape[1], img.shape[0]))\n",
    "plt.matshow(heatmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1223477",
   "metadata": {},
   "outputs": [],
   "source": [
    "oldMax = max(map(max, heatmap)) \n",
    "oldMin = min(map(min, heatmap)) \n",
    "newMin = 0\n",
    "newMax = 255\n",
    "    \n",
    "for i in range(255):\n",
    "    for j in range(255):\n",
    "        if heatmap[i][j] > oldMax/4:\n",
    "            heatmap[i][j] = (((heatmap[i][j] - oldMin) * (newMax - newMin)) / (oldMax - oldMin)) + newMin\n",
    "        else:\n",
    "            heatmap[i][j] = ((((heatmap[i][j] - oldMin) * (newMax - newMin)) / (oldMax - oldMin)) + newMin)/1.4\n",
    "\n",
    "\n",
    "\n",
    "heatmap = np.uint8(1 * heatmap)\n",
    "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "superimposed_img = heatmap * 0.85  + img\n",
    "cv2.imwrite('./CAM_images/map.jpg', superimposed_img)\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b086d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
