{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ce46603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7880bda8",
   "metadata": {},
   "source": [
    "## ImageAugmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db0ee681",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageAugmentation:\n",
    "    def __init__(self, path = \"./\"):\n",
    "        self.dim = (64, 36)\n",
    "        self.folder_list = glob.glob(path + \"/*\")\n",
    "        self.folders = []\n",
    "        for p in self.folder_list:\n",
    "            self.folders.append(p.split(\"\\\\\")[-1])\n",
    "            \n",
    "        \n",
    "        \n",
    "        for folder in self.folders:\n",
    "            self.files = glob.glob(path + \"/\" + folder + \"/*\")\n",
    "            \n",
    "            for file in self.files:\n",
    "                #resize\n",
    "                file_name = file.split(\"\\\\\")[-1]\n",
    "                img = cv2.imread(path + \"/\" + folder + \"/\" + file_name)\n",
    "                resized = cv2.resize(img, self.dim,interpolation=cv2.INTER_AREA)                \n",
    "                cv2.imwrite(path + \"/\" + folder + \"/\" + file_name,resized)\n",
    "                \n",
    "                \n",
    "                constraint = [\"rx_\", \"ry_\"]\n",
    "                if file_name[:3] not in constraint and path.split('/')[-1] != 'test':\n",
    "                    rows, cols, dim = resized.shape\n",
    "                    My = np.float32([[-1,  0, cols],\n",
    "                                    [0 ,  1, 0   ],\n",
    "                                    [0 ,  0, 1   ]])\n",
    "                    Mx = np.float32([[1,  0, 0],\n",
    "                                    [0 ,  -1, rows],\n",
    "                                    [0 ,  0, 1   ]])\n",
    "                    #resized img reflection on y axis\n",
    "                    reflected_img = cv2.warpPerspective(resized,My,(int(cols),int(rows)))\n",
    "                    cv2.imwrite(path + \"/\" + folder + \"/\" + \"ry_\"+ file_name,reflected_img)\n",
    "                    \n",
    "                    #resized img reflection on x axis\n",
    "                    reflected_img = cv2.warpPerspective(resized,Mx,(int(cols),int(rows)))\n",
    "                    cv2.imwrite(path + \"/\" + folder + \"/\" + \"rx_\"+ file_name,reflected_img)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cdeb289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize i reflect \n",
    "#ImageAugmentation(\"./data/train\")\n",
    "#ImageAugmentation(\"./data/test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d850c977",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af34e0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDataset(Dataset):\n",
    "    def __init__(self, train = False, test = False):\n",
    "        if(train):\n",
    "            self.data_path = \"./data/train/\"\n",
    "        if(test):\n",
    "            self.data_path = \"./data/test/\"\n",
    "        self.folder_list = glob.glob(self.data_path + \"*\")\n",
    "\n",
    "        self.data = []\n",
    "        for folder in self.folder_list:\n",
    "            folder_name = folder.split(\"\\\\\")[-1]\n",
    "            for img_path in glob.glob(self.data_path + folder_name + \"/*.jpg\"):\n",
    "                self.data.append([img_path, folder_name])\n",
    "        self.class_map = {\"Car\": 0, \"Truck\": 1, \"Bicycle\": 2, \"Dog\": 3}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        img_path, class_name = self.data[i]\n",
    "        img = cv2.imread(img_path)\n",
    "        class_id = self.class_map[class_name]\n",
    "        img_tensor = torch.tensor(img, dtype=torch.float)\n",
    "        img_tensor = img_tensor.permute(2,0,1)\n",
    "        class_id = torch.tensor([class_id])\n",
    "        return img_tensor, class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25bf4eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    batch_size = 5\n",
    "    train_dataset = CDataset(train=True)\n",
    "    data_loader_train = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    test_dataset = CDataset(test=True)\n",
    "    data_loader_test = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "    #for imgs, labels in data_loader:\n",
    "        #print(\"Batch of images has shape: \",imgs.shape)\n",
    "        #print(\"Batch of labels has shape: \", labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e6c961",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd5ce841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d27159ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\") \n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d7b2c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv_layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.PReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.PReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.PReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.PReLU(),\n",
    "            \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Dropout(p=0.6), \n",
    "            nn.Linear(18432, 4096),\n",
    "            nn.PReLU(),\n",
    "            nn.Dropout(p=0.6), \n",
    "            nn.Linear(4096, 256),\n",
    "            nn.PReLU(),\n",
    "            nn.Dropout(p=0.6),\n",
    "            nn.Linear(256, len(train_dataset.class_map)),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x): \n",
    "        x = self.conv_layer(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc_layer(x)\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fd468bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18432"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = CNN()\n",
    "def calc_input_dims():\n",
    "        batch_data = torch.zeros((1, 3, 64, 36))\n",
    "        \n",
    "        batch_data = net.conv_layer(batch_data)\n",
    "        \n",
    "        return int(np.prod(batch_data.size()))\n",
    "calc_input_dims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5630198e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossF = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af58407b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch #0\n",
      "Starting epoch #1\n",
      "Starting epoch #2\n",
      "Starting epoch #3\n",
      "Starting epoch #4\n",
      "Starting epoch #5\n",
      "Starting epoch #6\n",
      "Starting epoch #7\n",
      "Starting epoch #8\n",
      "Starting epoch #9\n",
      "Starting epoch #10\n",
      "Starting epoch #11\n",
      "Starting epoch #12\n",
      "Starting epoch #13\n",
      "Starting epoch #14\n",
      "Starting epoch #15\n",
      "Starting epoch #16\n",
      "Starting epoch #17\n",
      "Starting epoch #18\n",
      "Starting epoch #19\n",
      "Starting epoch #20\n",
      "Starting epoch #21\n",
      "Starting epoch #22\n",
      "Starting epoch #23\n",
      "Starting epoch #24\n",
      "Starting epoch #25\n",
      "Starting epoch #26\n",
      "Starting epoch #27\n",
      "Starting epoch #28\n",
      "Starting epoch #29\n",
      "Starting epoch #30\n",
      "Starting epoch #31\n",
      "Starting epoch #32\n",
      "Starting epoch #33\n",
      "Starting epoch #34\n",
      "Starting epoch #35\n",
      "Starting epoch #36\n",
      "Starting epoch #37\n",
      "Starting epoch #38\n",
      "Starting epoch #39\n",
      "Starting epoch #40\n",
      "Starting epoch #41\n",
      "Starting epoch #42\n",
      "Starting epoch #43\n",
      "Starting epoch #44\n",
      "Starting epoch #45\n",
      "Starting epoch #46\n",
      "Starting epoch #47\n",
      "Starting epoch #48\n",
      "Starting epoch #49\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "net.to(device)  \n",
    "epochs = 50\n",
    "loss_array = []\n",
    "\n",
    "for epoch in range(epochs): \n",
    "    print(\"Starting epoch #\" + str(epoch))\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(data_loader_train, 0):\n",
    "        # inputs, labels = data\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = lossF(outputs, labels.flatten())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        #if i % 100 == 0 and i != 0: \n",
    "            #print('loss: %.3f' %\n",
    "                  #running_loss))\n",
    "            #running_loss = 0.0\n",
    "    loss_array.append(float(running_loss))\n",
    "    \n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b930868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(epochs)\n",
    "y = np.array(loss_array)\n",
    "plt.title('Loss over epochs')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc25e408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv_layer): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): PReLU(num_parameters=1)\n",
       "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): PReLU(num_parameters=1)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): PReLU(num_parameters=1)\n",
       "    (8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): PReLU(num_parameters=1)\n",
       "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc_layer): Sequential(\n",
       "    (0): Dropout(p=0.6, inplace=False)\n",
       "    (1): Linear(in_features=18432, out_features=4096, bias=True)\n",
       "    (2): PReLU(num_parameters=1)\n",
       "    (3): Dropout(p=0.6, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=256, bias=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Dropout(p=0.6, inplace=False)\n",
       "    (7): Linear(in_features=256, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.to(torch.device(\"cpu\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c5c01666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 40\n",
      "Accuracy on test images: 80 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "predict = []\n",
    "true = []\n",
    "\n",
    "def find_max_elem(array):\n",
    "    _max = float('-inf')\n",
    "    index = 0\n",
    "    for i in range(len(array)):\n",
    "        if array[i] > _max:\n",
    "            index = i\n",
    "            _max = array[i]\n",
    "    return index\n",
    "            \n",
    "with torch.no_grad():\n",
    "    for data in data_loader_test:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            try:\n",
    "                true.append(int(labels[i]))\n",
    "                predict.append(find_max_elem(outputs[i]))\n",
    "                if find_max_elem(outputs[i]) == labels[i]:\n",
    "                    correct += 1\n",
    "                total+=1\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    print(correct, total)\n",
    "\n",
    "print('Accuracy on test images: %d %%' % (\n",
    "    round(100 * correct / total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "64c5de5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(true, predict)\n",
    "\n",
    "class Confusion_matrix():\n",
    "    def __init__(self):\n",
    "        self.M = []\n",
    "        self.class_map = {\"Car\": 0, \"Truck\": 1, \"Bicycle\": 2, \"Dog\": 3}\n",
    "\n",
    "    def extract_all(self, CM):\n",
    "        for k in range(4):\n",
    "            tp, fn, fp, tn = 0, 0, 0, 0\n",
    "            for i in range(4):\n",
    "                for j in range(4):\n",
    "                    if i == j and i == k:\n",
    "                        tp = CM[i][j]\n",
    "                    elif i == k and (j > i or j < i):\n",
    "                        fn += CM[i][j]\n",
    "                    elif j == k and (i > j or i < j):\n",
    "                        fp += CM[i][j]\n",
    "                    else:\n",
    "                        tn += CM[i][j]\n",
    "            self.M.append([tn, fp, fn, tp])  \n",
    "            \n",
    "            \n",
    "        for i in range(4):\n",
    "            position = list(self.class_map.values()).index(i)\n",
    "            print(\"Class: \", list(self.class_map.keys())[position])\n",
    "            print(\"[tn, fp, fn, tp]: \", self.M[i])\n",
    "            print(\"Accuracy: \", self.accuracy(i))\n",
    "            print(\"Misclassification: \", self.misclassification(i))\n",
    "            print(\"Precision: \", self.precision(i))\n",
    "            print(\"Recall: \", self.recall(i))\n",
    "            print(\"*********************************************\")\n",
    "    \n",
    "    def tn_fp_fn_tp(self, _class):\n",
    "        return self.M[_class]\n",
    "    \n",
    "    def accuracy(self, _class):\n",
    "        tn, fp, fn, tp = self.M[_class]\n",
    "        return (tp+tn)/(tp+tn+fp+fn) * 100\n",
    "    \n",
    "    def misclassification(self, _class):\n",
    "        tn, fp, fn, tp = self.M[_class]\n",
    "        return (fp+fn)/(tp+tn+fp+fn) * 100\n",
    "    \n",
    "    def precision(self, _class):\n",
    "        tn, fp, fn, tp = self.M[_class]\n",
    "        return tp/(tp+fp) * 100\n",
    "    \n",
    "    def recall(self, _class):\n",
    "        tn, fp, fn, tp = self.M[_class]\n",
    "        return tp/(tp+fn) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0e23f823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class:  Car\n",
      "[tn, fp, fn, tp]:  [29, 1, 2, 8]\n",
      "Accuracy:  92.5\n",
      "Misclassification:  7.5\n",
      "Precision:  88.88888888888889\n",
      "Recall:  80.0\n",
      "*********************************************\n",
      "Class:  Truck\n",
      "[tn, fp, fn, tp]:  [26, 4, 1, 9]\n",
      "Accuracy:  87.5\n",
      "Misclassification:  12.5\n",
      "Precision:  69.23076923076923\n",
      "Recall:  90.0\n",
      "*********************************************\n",
      "Class:  Bicycle\n",
      "[tn, fp, fn, tp]:  [29, 1, 1, 9]\n",
      "Accuracy:  95.0\n",
      "Misclassification:  5.0\n",
      "Precision:  90.0\n",
      "Recall:  90.0\n",
      "*********************************************\n",
      "Class:  Dog\n",
      "[tn, fp, fn, tp]:  [28, 2, 4, 6]\n",
      "Accuracy:  85.0\n",
      "Misclassification:  15.0\n",
      "Precision:  75.0\n",
      "Recall:  60.0\n",
      "*********************************************\n"
     ]
    }
   ],
   "source": [
    "a = Confusion_matrix()\n",
    "a.extract_all(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42847f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"./CNNmodule\"\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fcfca68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv_layer): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): PReLU(num_parameters=1)\n",
       "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): PReLU(num_parameters=1)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): PReLU(num_parameters=1)\n",
       "    (8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): PReLU(num_parameters=1)\n",
       "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc_layer): Sequential(\n",
       "    (0): Dropout(p=0.6, inplace=False)\n",
       "    (1): Linear(in_features=18432, out_features=4096, bias=True)\n",
       "    (2): PReLU(num_parameters=1)\n",
       "    (3): Dropout(p=0.6, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=256, bias=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Dropout(p=0.6, inplace=False)\n",
       "    (7): Linear(in_features=256, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN()\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
