{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ce46603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7880bda8",
   "metadata": {},
   "source": [
    "## ImageAugmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db0ee681",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageAugmentation:\n",
    "    def __init__(self, path = \"./\"):\n",
    "        self.dim = (64, 36)\n",
    "        self.folder_list = glob.glob(path + \"/*\")\n",
    "        self.folders = []\n",
    "        for p in self.folder_list:\n",
    "            self.folders.append(p.split(\"\\\\\")[-1])\n",
    "            \n",
    "        \n",
    "        \n",
    "        for folder in self.folders:\n",
    "            self.files = glob.glob(path + \"/\" + folder + \"/*\")\n",
    "            \n",
    "            for file in self.files:\n",
    "                #resize\n",
    "                file_name = file.split(\"\\\\\")[-1]\n",
    "                img = cv2.imread(path + \"/\" + folder + \"/\" + file_name)\n",
    "                resized = cv2.resize(img, self.dim,interpolation=cv2.INTER_AREA)                \n",
    "                cv2.imwrite(path + \"/\" + folder + \"/\" + file_name,resized)\n",
    "                \n",
    "                \n",
    "                constraint = [\"rx_\", \"ry_\"]\n",
    "                if file_name[:3] not in constraint and path.split('/')[-1] != 'test':\n",
    "                    rows, cols, dim = resized.shape\n",
    "                    My = np.float32([[-1,  0, cols],\n",
    "                                    [0 ,  1, 0   ],\n",
    "                                    [0 ,  0, 1   ]])\n",
    "                    Mx = np.float32([[1,  0, 0],\n",
    "                                    [0 ,  -1, rows],\n",
    "                                    [0 ,  0, 1   ]])\n",
    "                    #resized img reflection on y axis\n",
    "                    reflected_img = cv2.warpPerspective(resized,My,(int(cols),int(rows)))\n",
    "                    cv2.imwrite(path + \"/\" + folder + \"/\" + \"ry_\"+ file_name,reflected_img)\n",
    "                    \n",
    "                    #resized img reflection on x axis\n",
    "                    reflected_img = cv2.warpPerspective(resized,Mx,(int(cols),int(rows)))\n",
    "                    cv2.imwrite(path + \"/\" + folder + \"/\" + \"rx_\"+ file_name,reflected_img)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8cdeb289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.jpg\n",
      "b.jpg\n",
      "c.jpg\n",
      "d.jpg\n",
      "e.jpg\n",
      "f.jpg\n",
      "g.jpg\n",
      "h.jpg\n",
      "i.jpg\n",
      "j.jpg\n",
      "carA.jpg\n",
      "carB.jpg\n",
      "carC.jpg\n",
      "carD.jpg\n",
      "carE.jpg\n",
      "carF.jpg\n",
      "carG.jpg\n",
      "carH.jpg\n",
      "carI.jpg\n",
      "carJ.jpg\n",
      "doggo1.jpg\n",
      "doggo10.jpg\n",
      "doggo2.jpg\n",
      "doggo3.jpg\n",
      "doggo4.jpg\n",
      "doggo5.jpg\n",
      "doggo6.jpg\n",
      "doggo7.jpg\n",
      "doggo8.jpg\n",
      "doggo9.jpg\n",
      "a.jpg\n",
      "b.jpg\n",
      "c.jpg\n",
      "d.jpg\n",
      "e.jpg\n",
      "f.jpg\n",
      "g.jpg\n",
      "h.jpg\n",
      "i.jpg\n",
      "j.jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ImageAugmentation at 0x1d3e24d6c40>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resize i reflect \n",
    "ImageAugmentation(\"./data/train\")\n",
    "ImageAugmentation(\"./data/test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d850c977",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af34e0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDataset(Dataset):\n",
    "    def __init__(self, train = False, test = False):\n",
    "        if(train):\n",
    "            self.data_path = \"./data/train/\"\n",
    "        if(test):\n",
    "            self.data_path = \"./data/test/\"\n",
    "        self.folder_list = glob.glob(self.data_path + \"*\")\n",
    "\n",
    "        self.data = []\n",
    "        for folder in self.folder_list:\n",
    "            folder_name = folder.split(\"\\\\\")[-1]\n",
    "            for img_path in glob.glob(self.data_path + folder_name + \"/*.jpg\"):\n",
    "                self.data.append([img_path, folder_name])\n",
    "        self.class_map = {\"Car\": 0, \"Truck\": 1, \"Bicycle\": 2, \"Dog\": 3}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        img_path, class_name = self.data[i]\n",
    "        img = cv2.imread(img_path)\n",
    "        class_id = self.class_map[class_name]\n",
    "        img_tensor = torch.tensor(img, dtype=torch.float)\n",
    "        img_tensor = img_tensor.permute(2,0,1)\n",
    "        class_id = torch.tensor([class_id])\n",
    "        return img_tensor, class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25bf4eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    batch_size = 5\n",
    "    train_dataset = CDataset(train=True)\n",
    "    data_loader_train = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    test_dataset = CDataset(test=True)\n",
    "    data_loader_test = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "    #for imgs, labels in data_loader:\n",
    "        #print(\"Batch of images has shape: \",imgs.shape)\n",
    "        #print(\"Batch of labels has shape: \", labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e6c961",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd5ce841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d27159ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\") \n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d7b2c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv_layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #nadodo\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Dropout(p=0.4), \n",
    "            nn.Linear(18432, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.4), \n",
    "            nn.Linear(4096, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.4),\n",
    "            nn.Linear(256, len(train_dataset.class_map)),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x): \n",
    "        x = self.conv_layer(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc_layer(x)\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fd468bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18432"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = CNN()\n",
    "def calc_input_dims():\n",
    "        batch_data = torch.zeros((1, 3, 64, 36))\n",
    "        \n",
    "        batch_data = net.conv_layer(batch_data)\n",
    "        \n",
    "        return int(np.prod(batch_data.size()))\n",
    "calc_input_dims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5630198e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossF = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af58407b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch #0\n",
      "loss: 149.089\n",
      "loss: 107.513\n",
      "Starting epoch #1\n",
      "loss: 93.811\n",
      "loss: 82.826\n",
      "Starting epoch #2\n",
      "loss: 68.135\n",
      "loss: 61.798\n",
      "Starting epoch #3\n",
      "loss: 53.231\n",
      "loss: 46.527\n",
      "Starting epoch #4\n",
      "loss: 39.256\n",
      "loss: 38.457\n",
      "Starting epoch #5\n",
      "loss: 36.864\n",
      "loss: 30.405\n",
      "Starting epoch #6\n",
      "loss: 25.137\n",
      "loss: 22.171\n",
      "Starting epoch #7\n",
      "loss: 23.401\n",
      "loss: 17.006\n",
      "Starting epoch #8\n",
      "loss: 20.033\n",
      "loss: 16.154\n",
      "Starting epoch #9\n",
      "loss: 15.243\n",
      "loss: 18.558\n",
      "Starting epoch #10\n",
      "loss: 12.552\n",
      "loss: 10.344\n",
      "Starting epoch #11\n",
      "loss: 14.622\n",
      "loss: 7.929\n",
      "Starting epoch #12\n",
      "loss: 8.494\n",
      "loss: 14.208\n",
      "Starting epoch #13\n",
      "loss: 4.964\n",
      "loss: 7.131\n",
      "Starting epoch #14\n",
      "loss: 6.731\n",
      "loss: 12.749\n",
      "Starting epoch #15\n",
      "loss: 3.561\n",
      "loss: 7.896\n",
      "Starting epoch #16\n",
      "loss: 11.980\n",
      "loss: 2.900\n",
      "Starting epoch #17\n",
      "loss: 3.891\n",
      "loss: 4.467\n",
      "Starting epoch #18\n",
      "loss: 1.899\n",
      "loss: 4.815\n",
      "Starting epoch #19\n",
      "loss: 4.529\n",
      "loss: 1.450\n",
      "Starting epoch #20\n",
      "loss: 11.683\n",
      "loss: 2.941\n",
      "Starting epoch #21\n",
      "loss: 8.448\n",
      "loss: 9.034\n",
      "Starting epoch #22\n",
      "loss: 2.911\n",
      "loss: 5.826\n",
      "Starting epoch #23\n",
      "loss: 3.267\n",
      "loss: 8.275\n",
      "Starting epoch #24\n",
      "loss: 9.016\n",
      "loss: 5.033\n",
      "Starting epoch #25\n",
      "loss: 8.533\n",
      "loss: 6.574\n",
      "Starting epoch #26\n",
      "loss: 3.012\n",
      "loss: 4.147\n",
      "Starting epoch #27\n",
      "loss: 2.212\n",
      "loss: 5.520\n",
      "Starting epoch #28\n",
      "loss: 0.765\n",
      "loss: 1.734\n",
      "Starting epoch #29\n",
      "loss: 11.441\n",
      "loss: 7.654\n",
      "Starting epoch #30\n",
      "loss: 0.544\n",
      "loss: 0.617\n",
      "Starting epoch #31\n",
      "loss: 0.243\n",
      "loss: 1.464\n",
      "Starting epoch #32\n",
      "loss: 3.216\n",
      "loss: 12.601\n",
      "Starting epoch #33\n",
      "loss: 4.578\n",
      "loss: 7.770\n",
      "Starting epoch #34\n",
      "loss: 6.609\n",
      "loss: 4.022\n",
      "Starting epoch #35\n",
      "loss: 2.854\n",
      "loss: 0.528\n",
      "Starting epoch #36\n",
      "loss: 3.566\n",
      "loss: 1.330\n",
      "Starting epoch #37\n",
      "loss: 9.079\n",
      "loss: 3.632\n",
      "Starting epoch #38\n",
      "loss: 3.576\n",
      "loss: 2.018\n",
      "Starting epoch #39\n",
      "loss: 9.198\n",
      "loss: 5.716\n",
      "Starting epoch #40\n",
      "loss: 6.757\n",
      "loss: 0.676\n",
      "Starting epoch #41\n",
      "loss: 0.276\n",
      "loss: 4.983\n",
      "Starting epoch #42\n",
      "loss: 3.875\n",
      "loss: 3.028\n",
      "Starting epoch #43\n",
      "loss: 0.378\n",
      "loss: 10.123\n",
      "Starting epoch #44\n",
      "loss: 3.781\n",
      "loss: 2.963\n",
      "Starting epoch #45\n",
      "loss: 3.268\n",
      "loss: 8.610\n",
      "Starting epoch #46\n",
      "loss: 0.335\n",
      "loss: 0.177\n",
      "Starting epoch #47\n",
      "loss: 0.348\n",
      "loss: 9.274\n",
      "Starting epoch #48\n",
      "loss: 5.956\n",
      "loss: 0.712\n",
      "Starting epoch #49\n",
      "loss: 0.149\n",
      "loss: 2.850\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "net.to(device)  \n",
    "\n",
    "for epoch in range(50): \n",
    "    print(\"Starting epoch #\" + str(epoch))\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(data_loader_train, 0):\n",
    "        # inputs, labels = data\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = lossF(outputs, labels.flatten())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 0 and i != 0: \n",
    "            print('loss: %.3f' %\n",
    "                  (running_loss))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc25e408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv_layer): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU(inplace=True)\n",
       "    (11): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc_layer): Sequential(\n",
       "    (0): Dropout(p=0.4, inplace=False)\n",
       "    (1): Linear(in_features=18432, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=256, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Dropout(p=0.4, inplace=False)\n",
       "    (7): Linear(in_features=256, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.to(torch.device(\"cpu\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5c01666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 40\n",
      "Accuracy of the network test images: 82 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in data_loader_test:\n",
    "        total += len(data[0])\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            try:\n",
    "                if outputs[i][int(labels[i])] == torch.max(outputs[i]):\n",
    "                    correct += 1\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "    print(correct, total)\n",
    "    \n",
    "print('Accuracy of the network test images: %d %%' % (\n",
    "    round(100 * correct / total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42847f6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcfca68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
