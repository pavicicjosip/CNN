{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ce46603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7880bda8",
   "metadata": {},
   "source": [
    "## ImageAugmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db0ee681",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageAugmentation:\n",
    "    def __init__(self, path):\n",
    "        self.dim = (1280, 720)\n",
    "        self.folder_list = glob.glob(path + \"/*\")\n",
    "        self.folders = []\n",
    "        for p in self.folder_list:\n",
    "            self.folders.append(p.split(\"\\\\\")[-1])\n",
    "        \n",
    "        \n",
    "        for folder in self.folders:\n",
    "            self.file_names = []\n",
    "            self.files = glob.glob(path + \"/\" + folder + \"/*\")\n",
    "            for file in self.files:\n",
    "                #resize\n",
    "                self.file_names.append(file.split(\"\\\\\")[-1])\n",
    "                img = cv2.imread(path + \"/\" + folder + \"/\" + self.file_names[-1])\n",
    "                resized = cv2.resize(img, self.dim,interpolation=cv2.INTER_AREA)                \n",
    "                cv2.imwrite(path + \"/\" + folder + \"/\" + self.file_names[-1],resized)\n",
    "                \n",
    "                #resized img reflection\n",
    "                if self.file_names[-1][:2] != \"r_\":\n",
    "                    rows, cols, dim = resized.shape\n",
    "                    M = np.float32([[-1,  0, cols],\n",
    "                                    [0 ,  1, 0   ],\n",
    "                                    [0 ,  0, 1   ]])\n",
    "                    reflected_img = cv2.warpPerspective(resized,M,(int(cols),int(rows)))\n",
    "                    cv2.imwrite(path + \"/\" + folder + \"/\" + \"r_\"+ self.file_names[-1],reflected_img)\n",
    "                \n",
    "            \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cdeb289",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'resized' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-aa5eed3a4573>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mImageAugmentation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-14-9d5a8c8b9613>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m     23\u001b[0m                 \u001b[1;31m#resized img reflection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"r_\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                     \u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresized\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m                     M = np.float32([[-1,  0, cols],\n\u001b[0;32m     27\u001b[0m                                     \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;33m,\u001b[0m  \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m   \u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'resized' referenced before assignment"
     ]
    }
   ],
   "source": [
    "ImageAugmentation(\"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "af34e0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.data_path = \"./data/\"\n",
    "        self.folder_list = glob.glob(self.data_path + \"*\")\n",
    "\n",
    "        self.data = []\n",
    "        for folder in self.folder_list:\n",
    "            folder_name = folder.split(\"\\\\\")[-1]\n",
    "            for img_path in glob.glob(self.data_path + folder_name + \"/*.jpg\"):\n",
    "                self.data.append([img_path, folder_name])\n",
    "        self.class_map = {\"Car\": 0, \"Truck\": 1}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        img_path, class_name = self.data[i]\n",
    "        img = cv2.imread(img_path)\n",
    "        class_id = self.class_map[class_name]\n",
    "        img_tensor = torch.tensor(img, dtype=torch.float)\n",
    "        img_tensor = img_tensor.permute(2,0,1)\n",
    "        class_id = torch.tensor([class_id])\n",
    "        return img_tensor, class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "25bf4eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch of images has shape:  torch.Size([5, 3, 720, 1280])\n",
      "Batch of labels has shape:  torch.Size([5, 1])\n",
      "Batch of images has shape:  torch.Size([5, 3, 720, 1280])\n",
      "Batch of labels has shape:  torch.Size([5, 1])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    dataset = CDataset()\n",
    "    data_loader = DataLoader(dataset, batch_size=5, shuffle=True)\n",
    "    \n",
    "    for imgs, labels in data_loader:\n",
    "        print(\"Batch of images has shape: \",imgs.shape)\n",
    "        print(\"Batch of labels has shape: \", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74c47fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5ce841",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27159ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8d15fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cd5ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
